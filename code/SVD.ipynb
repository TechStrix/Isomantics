{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "from gensim_download import pickle_rw\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy.linalg\n",
    "\n",
    "from numpy.linalg import det\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import sympy as sympy\n",
    "\n",
    "from sympy import Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dict(vocab, vectors):\n",
    "    \"\"\"Make dictionary of vocab and vectors\"\"\"\n",
    "    return {vocab[i]: vectors[i] for i in range(len(vocab))}\n",
    "\n",
    "\n",
    "def vocab_train_test(embedding, lg1, lg2, lg1_vocab):\n",
    "    \"\"\"Create training and test vocabularies\"\"\"\n",
    "    if embedding == 'zeroshot':\n",
    "        with open('../data/zeroshot/transmat/data/' +\n",
    "                  'OPUS_en_it_europarl_train_5K.txt') as f:\n",
    "            vocab_train = [(_.split(' ')[0], _.split(' ')[1])\n",
    "                           for _ in f.read().split('\\n')[:-1]]\n",
    "        with open('../data/zeroshot/transmat/data/' +\n",
    "                  'OPUS_en_it_europarl_test.txt') as f:\n",
    "            vocab_test = [(_.split(' ')[0], _.split(' ')[1])\n",
    "                          for _ in f.read().split('\\n')[:-1]]\n",
    "\n",
    "    elif embedding in ['fasttext_random', 'fasttext_top']:\n",
    "        embedding, split = embedding.split('_')\n",
    "        lg1_lg2, lg2_lg1 = pickle_rw((lg1 + '_' + lg2, 0),\n",
    "                                     (lg2 + '_' + lg1, 0), write=False)\n",
    "        # T = Translation, R = Reverse (translated and then translated back)\n",
    "        # Create vocab from 2D translations\n",
    "        vocab_2D = []\n",
    "        for lg1_word in lg1_vocab:\n",
    "            # Translate lg1_word\n",
    "            if lg1_word in lg1_lg2:\n",
    "                lg1_word_T = lg1_lg2[lg1_word]\n",
    "\n",
    "                # Check if translated word (or lowercase) is in lg2_lg1\n",
    "                if lg1_word_T in lg2_lg1.keys():\n",
    "                    lg1_word_R = lg2_lg1[lg1_word_T]\n",
    "                elif lg1_word_T.lower() in lg2_lg1.keys():\n",
    "                    lg1_word_T = lg1_word_T.lower()\n",
    "                    lg1_word_R = lg2_lg1[lg1_word_T]\n",
    "                else:\n",
    "                    lg1_word_R = None\n",
    "\n",
    "                # Check if lg1_word and lg1_word_R are equal (lowercase)\n",
    "                if lg1_word_R:\n",
    "                    if lg1_word.lower() == lg1_word_R.lower():\n",
    "                        vocab_2D.append((lg1_word, lg1_word_T))\n",
    "        print('length of '+ lg1+'-'+ lg2+ ' vocab: '+str(len(vocab_2D)))\n",
    "\n",
    "        #Create Train/Test vocab\n",
    "\n",
    "        if split == 'random':\n",
    "            sample = np.random.choice(len(vocab_2D), 6500, replace=False)\n",
    "            vocab_train = np.asarray(vocab_2D)[sample[:5000]].tolist()\n",
    "            vocab_test = np.asarray(vocab_2D)[sample[5000:]].tolist()\n",
    "        elif split == 'top':\n",
    "            sample = np.random.choice(range(6500), 6500, replace=False)\n",
    "            vocab_train = np.asarray(vocab_2D)[:5000, :].tolist()\n",
    "            vocab_test = np.asarray(vocab_2D)[:1500, :].tolist()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # if split == 'random':\n",
    "        #     sample = np.random.choice(len(vocab_2D), 900, replace=False)\n",
    "        #     vocab_train = np.asarray(vocab_2D)[sample[:700]].tolist()\n",
    "        #     vocab_test = np.asarray(vocab_2D)[sample[700:]].tolist()\n",
    "        # elif split == 'top':\n",
    "        #     sample = np.random.choice(range(900), 900, replace=False)\n",
    "        #     vocab_train = np.asarray(vocab_2D)[:700, :].tolist()\n",
    "        #     vocab_test = np.asarray(vocab_2D)[:200, :].tolist()\n",
    "        # else:\n",
    "        #     pass\n",
    "\n",
    "    return vocab_train, vocab_test\n",
    "\n",
    "\n",
    "def vectors_train_test(vocab_train, vocab_test):\n",
    "    \"\"\"Create training and test vectors\"\"\"\n",
    "    X_train, y_train = zip(*[(lg1_dict[lg1_word], lg2_dict[lg2_word])\n",
    "                             for lg1_word, lg2_word in vocab_train])\n",
    "    X_test, y_test = zip(*[(lg1_dict[lg1_word], lg2_dict[lg2_word])\n",
    "                           for lg1_word, lg2_word in vocab_test])\n",
    "    return map(np.asarray, (X_train, X_test, y_train, y_test))\n",
    "\n",
    "\n",
    "def translation_matrix(X_train, y_train):\n",
    "    \"\"\"Fit translation matrix T\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, use_bias=False, input_shape=(X_train.shape[1],),kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=20,\n",
    "                        verbose=False)\n",
    "    T = model.get_weights()[0]\n",
    "\n",
    "    T = np.matrix(T)\n",
    "\n",
    "    M = np.multiply(np.matrix(T),100)\n",
    "\n",
    "    T_norm, T_normed = normalize(M)\n",
    "\n",
    "    D = np.linalg.det(M)\n",
    "    \n",
    "    I = inv(T)\n",
    "    \n",
    "    #Fr_norm = np.linalg.det(np.subtract(np.matmul(M,M.getH()),np.matmul(M.getH(),M)))\n",
    "    \n",
    "    Fr_norm = np.linalg.det(np.matrix(np.subtract(np.matmul(T,T.getH()),np.matmul(T.getH(),T))))\n",
    "    \n",
    "    #print(T_normed)\n",
    "    #print(T_normed.getH())\n",
    "\n",
    "    #print(np.around(np.matmul(T_normed,T_normed.getH())))\n",
    "\n",
    "    #print(np.around(np.matmul(T_normed.getH(),T_normed)))\n",
    "\n",
    "    print (\"Determinant:\"+str(D))\n",
    "    \n",
    "    #print (\"Fr_norm:\"+str(Fr_norm))\n",
    "\n",
    "    if np.array_equal(np.around(np.matmul(T_normed,T_normed.getH())), np.around(np.matmul(T_normed.getH(),T_normed))) == True:\n",
    "        tf = \"True\"\n",
    "    else:\n",
    "        tf = \"False\"\n",
    "\n",
    "    return model, history, T, D, tf, I, M\n",
    "\n",
    "def translation_accuracy(X_test, y_test):\n",
    "    \"\"\"Get predicted matrix 'yhat' using 'T' and find translation accuracy\"\"\"\n",
    "    # yhat\n",
    "    yhat = X.dot(T)\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if yhat[i,:].all() == y_test[i,:].all():\n",
    "            count = count + 1\n",
    "    accuracy = count/len(y_test)*100\n",
    "    return accuracy\n",
    "\n",
    "def svd(T):\n",
    "    \"\"\"Perform SVD on the translation matrix 'T' \"\"\"\n",
    "    U, s, Vh = numpy.linalg.svd(T, full_matrices=False )\n",
    "    return U, s, Vh\n",
    "\n",
    "def T_svd_EDA(s):\n",
    "    \"\"\"Perform SVD on the translation matrix 'T' \"\"\"\n",
    "    plt.hist(s, bins='auto', range = (0,1),normed = 1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize(matrix):\n",
    "    \"\"\"Normalize the rows of a matrix\"\"\"\n",
    "    matrix_norm = np.linalg.norm(matrix, axis=1)\n",
    "    matrix_normed = matrix / np.repeat(matrix_norm, matrix.shape[1]). \\\n",
    "        reshape(matrix.shape)\n",
    "    return matrix_norm, matrix_normed\n",
    "\n",
    "\n",
    "def translation_results(X, y, vocab, M, lg2_vectors, lg2_vocab):\n",
    "    \"\"\"X, y, vocab - The training or test data that you want results for\n",
    "    T - The translation matrix\n",
    "    lg2_vectors, lg2_vocab - Foreign language used to find the nearest neighbor\n",
    "    \"\"\"\n",
    "\n",
    "    # Data Prep on Inputs\n",
    "    X_word, y_word = zip(*vocab)\n",
    "    X_norm, X_normed = normalize(X)\n",
    "    y_norm, y_normed = normalize(y)\n",
    "    lg2_vectors_norm, lg2_vectors_normed = normalize(lg2_vectors)\n",
    "\n",
    "    # yhat\n",
    "    yhat = X.dot(M)\n",
    "    yhat_norm, yhat_normed = normalize(yhat)\n",
    "\n",
    "    #X_norm = normalize(X)\n",
    "\n",
    "\n",
    "    # Nearest Neighbors\n",
    "#     neg_cosine = -yhat_normed.dot(lg2_vectors_normed.T)\n",
    "#     ranked_neighbor_indices = np.argsort(neg_cosine, axis=1)\n",
    "\n",
    "#     # Nearest Neighbor\n",
    "#     nearest_neighbor_indices = ranked_neighbor_indices[:, 0]\n",
    "#     yhat_neighbor = lg2_vectors[nearest_neighbor_indices, :]\n",
    "#     yhat_neighbor_norm, yhat_neighbor_normed = normalize(yhat_neighbor)\n",
    "#     yhat_neighbor_word = np.asarray(lg2_vocab)[nearest_neighbor_indices]\n",
    "\n",
    "#     # Results DF\n",
    "#     cols = ['X_norm', 'y_norm', 'yhat_norm', 'yhat_neighbor_norm',\n",
    "#             'X_word', 'y_word', 'yhat_neighbor_word']\n",
    "#     results_df = pd.DataFrame({'X_norm': X_norm,\n",
    "#                                'y_norm': y_norm,\n",
    "#                                'yhat_norm': yhat_norm,\n",
    "#                                'yhat_neighbor_norm': yhat_neighbor_norm,\n",
    "#                                'X_word': X_word,\n",
    "#                                'y_word': y_word,\n",
    "#                                'yhat_neighbor_word': yhat_neighbor_word,})\n",
    "#     results_df = results_df[cols]\n",
    "#     results_df['neighbor_correct'] = results_df.y_word == \\\n",
    "#         results_df.yhat_neighbor_word\n",
    "\n",
    "    return yhat_norm\n",
    "\n",
    "\n",
    "def T_norm_EDA(results_df):\n",
    "    \"\"\"Plot result norms side-by-side\"\"\"\n",
    "    test_size = results_df.shape[0]\n",
    "    test_accuracy = round(results_df.neighbor_correct.mean(), 2)\n",
    "\n",
    "    print('Test Accuracy: '+str(test_accuracy)+'\\n')\n",
    "\n",
    "    plot_data = ['X_norm', 'y_norm', 'yhat_norm', 'yhat_neighbor_norm']\n",
    "    # f, ax = plt.subplots(len(plot_data), sharex=True, sharey=True,\n",
    "    #                      figsize=(10, 10))\n",
    "    # for i, d in enumerate(plot_data):\n",
    "    #     ax[i].hist(results_df[d], bins=100)\n",
    "    #     ax[i].axis('off')\n",
    "    #     title = '{}: mean={}, std={}'.format(d, round(results_df[d].mean(), 2), round(results_df[d].std(), 2))\n",
    "    #     ax[i].set_title(title)\n",
    "    # f.subplots_adjust(hspace=0.7)\n",
    "    # plt.savefig('../images/' + lg1 + '_' + lg2 + '_' + embedding +\n",
    "    #             '_T_norm.png')\n",
    "    # plt.close('all')\n",
    "    return\n",
    "\n",
    "\n",
    "def T_pca_EDA(T):\n",
    "    \"\"\"PCA on matrix T\"\"\"\n",
    "    T_ss = StandardScaler().fit_transform(T)\n",
    "    pca = PCA().fit(T_ss)\n",
    "    n = pca.n_components_\n",
    "\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.xlim((0, n))\n",
    "    # plt.ylim((0, 1))\n",
    "    # plt.plot(range(n + 1), [0] + np.cumsum(pca.explained_variance_ratio_).\n",
    "    #          tolist())\n",
    "    # plt.plot(range(n + 1), np.asarray(range(n + 1)) / n)\n",
    "    # plt.xlabel('Number of Eigenvectors')\n",
    "    # plt.ylabel('Explained Variance')\n",
    "    # plt.savefig('../images/' + lg1 + '_' + lg2 + '_' + embedding +\n",
    "    #             '_T_isotropy.png')\n",
    "    # plt.close('all')\n",
    "\n",
    "    isotropy = (1 - sum(np.cumsum(pca.explained_variance_ratio_) * 1 / n)) / .5\n",
    "    return isotropy\n",
    "\n",
    "\n",
    "def T_report_results(embedding, lg1, lg2, lg1_vectors, lg2_vectors,\n",
    "                     X_train, X_test, D, results_df, isotropy):\n",
    "    md = '## ' + lg1.title() + ' to ' + lg2.title() + ' ' + \\\n",
    "        embedding.title() + '  \\n'\n",
    "    md += '- ' + lg1.title() + ' Vocabulary Size = ' + \\\n",
    "        '{:,.0f}'.format(lg1_vectors.shape[0]) + '  \\n'\n",
    "    md += '- ' + lg1.title() + ' Embedding Length = ' + \\\n",
    "        '{:,.0f}'.format(lg1_vectors.shape[1]) + '  \\n'\n",
    "    md += '- ' + lg2.title() + ' Vocabulary Size = ' + \\\n",
    "        '{:,.0f}'.format(lg2_vectors.shape[0]) + '  \\n'\n",
    "    md += '- ' + lg2.title() + ' Embedding Length = ' + \\\n",
    "        '{:,.0f}'.format(lg2_vectors.shape[1]) + '  \\n'\n",
    "    md += '- Train Size = ' + '{:,.0f}'.format(X_train.shape[0]) + '  \\n'\n",
    "    md += '- Test Size = ' + '{:,.0f}'.format(X_test.shape[0]) + '  \\n'\n",
    "    md += '- Determinant = ' + '{:,.0f}'.format(D) + '  \\n'\n",
    "\n",
    "    md += '- <b>Test Accuracy = ' + \\\n",
    "        '{:,.1%}'.format(results_df.neighbor_correct.mean()) + '</b>  \\n\\n'\n",
    "\n",
    "\n",
    "\n",
    "    md += '#### Test L2 Norms  \\n'\n",
    "    md += '- X_norm: L2 norms for ' + lg1.title() + ' test vectors  \\n'\n",
    "    md += '- y_norm: L2 norms for ' + lg2.title() + ' test vectors  \\n'\n",
    "    md += '- yhat_norm: L2 norms for X.dot(T) test vectors ' + \\\n",
    "        '(T = translation matrix)  \\n'\n",
    "    md += '- yhat_neighbor norm: L2 norms for nearest neighbor' + \\\n",
    "        'to X.dot(T) in y test vectors  \\n'\n",
    "    md += '![](../images/' + lg1 + '_' + lg2 + '_' + embedding + \\\n",
    "        '_T_norm.png)  \\n\\n'\n",
    "\n",
    "    md += '#### Translation Matrix Isotropy  \\n'\n",
    "    md += '- Isotropy = ' + '{:,.1%}'.format(isotropy) + '  \\n'\n",
    "    md += '![](../images/' + lg1 + '_' + lg2 + '_' + embedding + \\\n",
    "        '_T_isotropy.png)  \\n\\n'\n",
    "\n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function ( with SVD stats )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->ru\n",
      "\n",
      "length of en-ru vocab: 6839\n",
      "Determinant:-1.63862e-20\n",
      "biggest element:0.0221742\n",
      "\n",
      "min: 6.52239e-05\n",
      "\n",
      "max: 0.665478\n",
      "\n",
      "mean: 0.0187613\n",
      "\n",
      "median: 0.0096022\n",
      "\n",
      "std: 0.0438961\n",
      "\n",
      "min: -4.18559\n",
      "\n",
      "max: -0.176866\n",
      "\n",
      "mean: -2.06595\n",
      "\n",
      "median: -2.01763\n",
      "\n",
      "std: 0.562375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1Mz/A74plpF4OyIaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11de1c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->de\n",
      "\n",
      "length of en-de vocab: 16693\n",
      "Determinant:-4.41618e-18\n",
      "biggest element:0.0258662\n",
      "\n",
      "min: 3.71876e-05\n",
      "\n",
      "max: 0.641488\n",
      "\n",
      "mean: 0.0186413\n",
      "\n",
      "median: 0.0100413\n",
      "\n",
      "std: 0.0423793\n",
      "\n",
      "min: -4.4296\n",
      "\n",
      "max: -0.192812\n",
      "\n",
      "mean: -2.05785\n",
      "\n",
      "median: -1.99821\n",
      "\n",
      "std: 0.559742\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e3e3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->es\n",
      "\n",
      "length of en-es vocab: 10422\n",
      "Determinant:-7.23562e-23\n",
      "biggest element:0.0245849\n",
      "\n",
      "min: 5.52891e-05\n",
      "\n",
      "max: 0.56203\n",
      "\n",
      "mean: 0.0171394\n",
      "\n",
      "median: 0.00972858\n",
      "\n",
      "std: 0.0372231\n",
      "\n",
      "min: -4.25736\n",
      "\n",
      "max: -0.25024\n",
      "\n",
      "mean: -2.0738\n",
      "\n",
      "median: -2.01195\n",
      "\n",
      "std: 0.543188\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naoSFLkmNsNAlqREWuiQ1wkKXpEb8H4OD882JS38UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12135b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->zh-CN\n",
      "\n",
      "length of en-zh-CN vocab: 1460\n",
      "Determinant:0.0\n",
      "biggest element:0.017664\n",
      "\n",
      "min: 3.56689e-05\n",
      "\n",
      "max: 0.534705\n",
      "\n",
      "mean: 0.0106303\n",
      "\n",
      "median: 0.00440673\n",
      "\n",
      "std: 0.0351788\n",
      "\n",
      "min: -4.44771\n",
      "\n",
      "max: -0.271886\n",
      "\n",
      "mean: -2.39793\n",
      "\n",
      "median: -2.35589\n",
      "\n",
      "std: 0.581548\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x140961ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d6a34b6d4267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0mlg2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_vocab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0mlg2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_vectors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                       write=False)\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mlg1_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg1_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg1_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlg2_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg2_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg2_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SkymindLabsInternship/Isomantics/code/gensim_download.py\u001b[0m in \u001b[0;36mpickle_rw\u001b[0;34m(write, *tuples)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../pickle/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Manually set list of translations (embedding, lg1, lg2)\n",
    "    translations = [#('fasttext_random', 'en', 'ru'),\n",
    "                    ('fasttext_top', 'en', 'ru'),\n",
    "                    #('fasttext_random', 'en', 'de'),\n",
    "                    ('fasttext_top', 'en', 'de'),\n",
    "                    #('fasttext_random', 'en', 'es'),\n",
    "                    ('fasttext_top', 'en', 'es'),\n",
    "                    #('fasttext_random', 'en', 'zh-CN'),\n",
    "                    ('fasttext_top', 'en', 'zh-CN'),\n",
    "                    #('fasttext_random', 'de', 'en'),\n",
    "                    ('fasttext_top', 'de', 'en'),\n",
    "                    #('fasttext_random', 'de', 'es'),\n",
    "                    ('fasttext_top', 'de', 'es'),\n",
    "                    #('fasttext_random', 'de', 'ru'),\n",
    "                    ('fasttext_top', 'de', 'ru'),\n",
    "                    #('fasttext_random', 'de', 'zh-CN'),\n",
    "                    ('fasttext_top', 'de', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'en'),\n",
    "                    ('fasttext_top', 'ru', 'en'),\n",
    "                    #('fasttext_random', 'ru', 'es'),\n",
    "                    ('fasttext_top', 'ru', 'es'),\n",
    "                    #('fasttext_random', 'ru', 'zh-CN'),\n",
    "                    ('fasttext_top', 'ru', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'de'),\n",
    "                    ('fasttext_top', 'ru', 'de'),\n",
    "                    #('fasttext_random', 'zh-CN', 'en'),\n",
    "                    ('fasttext_top', 'zh-CN', 'en'),\n",
    "                    #('fasttext_random', 'zh-CN', 'es'),\n",
    "                    ('fasttext_top', 'zh-CN', 'es'),\n",
    "                    #('fasttext_random', 'zh-CN', 'ru'),\n",
    "                    ('fasttext_top', 'zh-CN', 'ru'),\n",
    "                    #('fasttext_random', 'zh-CN', 'de'),\n",
    "                    ('fasttext_top', 'zh-CN', 'de'),\n",
    "                    #('fasttext_random', 'es', 'en'),\n",
    "                    ('fasttext_top', 'es', 'en'),\n",
    "                    #('fasttext_random', 'es', 'de'),\n",
    "                    ('fasttext_top', 'es', 'de'),\n",
    "                    #('fasttext_random', 'es', 'ru'),\n",
    "                    ('fasttext_top', 'es', 'ru'),\n",
    "                    #('fasttext_random', 'es', 'zh-CN'),\n",
    "                    ('fasttext_top', 'es', 'zh-CN')\n",
    "\n",
    "                    ]\n",
    "\n",
    "    md = ''\n",
    "    for translation in translations:\n",
    "        embedding, lg1, lg2 = translation\n",
    "        # Vocab/Vectors/Dicts\n",
    "        lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "            pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      write=False)\n",
    "        lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "        lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "        print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "        # Train/Test Vocab/Vectors\n",
    "        vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "        X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                              vocab_test)\n",
    "\n",
    "        # Fit tranlation matrix to training data\n",
    "        model, history, T, D, tf,I, M = translation_matrix(X_train, y_train)\n",
    "\n",
    "        print('biggest element:'+str(np.max(T))+'\\n')\n",
    "        \n",
    "        U,s,Vh = svd(T)\n",
    "        \n",
    "        #scaler = MinMaxScaler()\n",
    "        \n",
    "        #scaler.fit(s)\n",
    "        \n",
    "        #s = scaler.transform(s)\n",
    "        \n",
    "        print(\"min: \"+str(min(s))+\"\\n\")\n",
    "        \n",
    "        print(\"max: \"+str(max(s))+\"\\n\")\n",
    "        \n",
    "        print(\"mean: \"+str(np.mean(s))+\"\\n\")\n",
    "        \n",
    "        print(\"median: \"+str(np.median(s))+\"\\n\")\n",
    "        \n",
    "        print(\"std: \"+str(np.std(s))+\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        s = np.log10(s)\n",
    "        \n",
    "        print(\"min: \"+str(min(s))+\"\\n\")\n",
    "        \n",
    "        print(\"max: \"+str(max(s))+\"\\n\")\n",
    "        \n",
    "        print(\"mean: \"+str(np.mean(s))+\"\\n\")\n",
    "        \n",
    "        print(\"median: \"+str(np.median(s))+\"\\n\")\n",
    "        \n",
    "        print(\"std: \"+str(np.std(s))+\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(s)\n",
    "        \n",
    "        plt.hist(s,bins='auto')#bins=50,normed='True',range = (0.0,0.2))\n",
    "        #plt.plot(s)\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->ru\n",
      "\n",
      "length of en-ru vocab: 6839\n",
      "Determinant:6.68409e-20\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[  11.04030704  -58.05263901  -70.07519531 ...,   25.41628647\n",
      "    30.97108078  -40.67876816]\n",
      " [  91.81015015  155.81185913   63.31090164 ...,  -51.2548027   -34.41306305\n",
      "    47.90806961]\n",
      " [  23.46608734   12.1979866   -52.79821777 ...,   23.93603897\n",
      "    -7.66915035    5.51542711]\n",
      " ..., \n",
      " [ -95.40709686  -29.07827187   87.29953003 ...,  100.88738251  -16.7738266\n",
      "   153.37922668]\n",
      " [-147.87860107  -81.68314362  -44.3213768  ...,  173.213974    -59.09873962\n",
      "    59.42921829]\n",
      " [  16.56924438 -103.65172577 -142.10444641 ...,  -78.63152313\n",
      "   117.04570007 -168.28567505]]\n",
      "\n",
      "Translation: en->de\n",
      "\n",
      "length of en-de vocab: 16693\n",
      "Determinant:2.40427e-21\n",
      "Fr_norm:0.0\n",
      "Inverse:[[  755.14819336  -133.340271     206.62522888 ...,  1882.01904297\n",
      "   -709.5010376  -1083.3581543 ]\n",
      " [  242.50422668   -23.07047462     5.77775288 ...,   960.47021484\n",
      "   -322.10214233  -420.7321167 ]\n",
      " [ -431.28991699    97.79253387   -95.18783569 ..., -1025.21264648\n",
      "    330.7355957    584.13464355]\n",
      " ..., \n",
      " [ -422.92025757    46.88298035    96.03134155 ..., -1551.60412598\n",
      "    493.1998291    651.64038086]\n",
      " [  611.00964355  -180.95664978   202.88879395 ...,  1523.80834961\n",
      "   -622.27716064  -950.3012085 ]\n",
      " [ -259.61535645    10.06036949   -96.83132935 ...,  -761.62390137\n",
      "    190.62011719   434.51565552]]\n",
      "\n",
      "Translation: en->es\n",
      "\n",
      "length of en-es vocab: 10422\n",
      "Determinant:-1.16279e-23\n",
      "Fr_norm:0.0\n",
      "Inverse:[[ -98.68668365 -260.83862305 -587.78167725 ...,  379.01580811\n",
      "    57.62456131  647.65167236]\n",
      " [ -93.85202026   31.28058624  144.4175415  ...,  -42.15445328\n",
      "     3.08430982 -151.31071472]\n",
      " [ 284.58007812 -404.34399414 -712.90319824 ...,  552.19470215\n",
      "   -39.45856476  884.69006348]\n",
      " ..., \n",
      " [ 200.77197266 -179.4989624  -525.70465088 ...,  256.63024902\n",
      "   -38.14390945  414.31124878]\n",
      " [-100.97593689 -223.18373108 -465.73358154 ...,  310.7088623    63.51074219\n",
      "   427.6505127 ]\n",
      " [-123.85021973 -202.60536194 -432.22723389 ...,  316.81027222\n",
      "    15.20920467  519.00701904]]\n",
      "\n",
      "Translation: en->zh-CN\n",
      "\n",
      "length of en-zh-CN vocab: 1460\n",
      "Determinant:-0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[ 279.08325195  -50.90645218  174.09918213 ...,   90.67852783\n",
      "  -125.23526001  138.2858429 ]\n",
      " [ 282.04492188  -24.62430573  276.77432251 ...,  248.19404602\n",
      "   -95.89566803  -59.2610321 ]\n",
      " [  -3.75852799 -152.42700195   65.89362335 ...,  302.29708862\n",
      "  -105.84304047 -232.65254211]\n",
      " ..., \n",
      " [ 211.2144165  -100.81359863  124.05513    ...,  331.4234314  -124.95433044\n",
      "  -216.73834229]\n",
      " [-125.23327637  128.56265259   89.98539734 ...,  -53.60145569\n",
      "    78.57273102   57.74006271]\n",
      " [ 179.14727783  -62.25080872  120.82265472 ...,  -73.63300323\n",
      "   103.99213409   30.01247787]]\n",
      "\n",
      "Translation: de->en\n",
      "\n",
      "length of de-en vocab: 16693\n",
      "Determinant:-2.15217e-17\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[   1.84647417  -55.90779495  -43.97912598 ...,   39.81010818\n",
      "   -39.84086227 -105.50863647]\n",
      " [  91.50335693  135.40769958  272.12155151 ...,  170.50970459\n",
      "   -79.33867645 -129.79850769]\n",
      " [  -1.02397203   67.86239624   -5.41641092 ...,   94.55872345\n",
      "  -108.43566895  -34.19537735]\n",
      " ..., \n",
      " [ -55.88882065  -73.20679474 -167.59153748 ...,  -99.45224762\n",
      "    50.38871765   40.59305191]\n",
      " [  71.21019745   31.15022278  143.98403931 ...,   29.07103348\n",
      "   -51.79080582  -67.52401733]\n",
      " [   1.01958323   -3.17144513   -0.39861795 ...,  -27.27108765   64.1984024\n",
      "    79.6170578 ]]\n",
      "\n",
      "Translation: de->es\n",
      "\n",
      "length of de-es vocab: 11456\n",
      "Determinant:4.61531e-23\n",
      "Fr_norm:0.0\n",
      "Inverse:[[-208.12774658  129.30685425  286.38415527 ...,  161.75546265\n",
      "   -65.80812836 -153.16976929]\n",
      " [  47.54762268  -11.62705421   95.54808807 ...,  122.13251495\n",
      "    95.22483063 -182.45480347]\n",
      " [ -68.93095398   29.17188644   10.01784801 ...,   80.02574921\n",
      "   -23.01441765  -80.31826782]\n",
      " ..., \n",
      " [ -60.41200256   46.29036331   83.87097168 ...,  -34.00827026\n",
      "  -115.82743073  -35.87575531]\n",
      " [-335.98999023   66.93195343  189.75874329 ...,   24.15080833\n",
      "  -275.91699219   87.48773193]\n",
      " [   1.96587789  -25.36977577  105.56586456 ...,  206.55760193\n",
      "    43.54348755 -296.44512939]]\n",
      "\n",
      "Translation: de->ru\n",
      "\n",
      "length of de-ru vocab: 5910\n",
      "Determinant:-1.09467e-19\n",
      "Fr_norm:0.0\n",
      "Inverse:[[-151.40771484  -30.88466072   77.30550385 ...,   38.58583069\n",
      "   128.15287781  -20.5597744 ]\n",
      " [ -38.43872452  -37.58361816  -96.61126709 ...,   37.91732788\n",
      "   100.82440948   20.59609604]\n",
      " [-176.77554321   23.42058182   27.32201767 ...,  -75.23674011\n",
      "   106.20679474 -273.70327759]\n",
      " ..., \n",
      " [-194.94673157   -2.72268939 -151.26535034 ..., -133.86204529\n",
      "   145.88725281 -384.5640564 ]\n",
      " [  70.48829651  -24.49956322  -85.98475647 ...,  -49.60044098\n",
      "   -56.12587738  -85.30728912]\n",
      " [-378.18856812    7.60398245  -20.77565765 ..., -214.16625977\n",
      "    72.85224152 -715.15490723]]\n",
      "\n",
      "Translation: de->zh-CN\n",
      "\n",
      "length of de-zh-CN vocab: 1820\n",
      "Determinant:0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[  182.77256775   -12.98318291     8.14419556 ...,   -44.43376541\n",
      "     78.37240601   -77.56101227]\n",
      " [   80.42079163  -243.8031311   -268.67929077 ...,   112.42276764\n",
      "     37.31299591  -114.50111389]\n",
      " [  780.19976807  -752.38586426  -606.61517334 ...,  -107.82647705\n",
      "    144.76489258  -893.77630615]\n",
      " ..., \n",
      " [ -113.08462524   269.40768433   195.55578613 ...,   -34.58014297\n",
      "   -143.97172546   110.33963776]\n",
      " [  214.31100464  -313.65765381   -16.46645927 ...,   -42.66078186\n",
      "    139.57568359  -233.36196899]\n",
      " [  653.07806396 -1090.84179688  -776.70593262 ...,    27.33714294\n",
      "    350.93087769  -820.984375  ]]\n",
      "\n",
      "Translation: ru->en\n",
      "\n",
      "length of ru-en vocab: 6839\n",
      "Determinant:-1.14019e-20\n",
      "Fr_norm:0.0\n",
      "Inverse:[[-234.50318909   22.7103157   468.10519409 ..., -142.00621033\n",
      "   224.19677734 -438.63296509]\n",
      " [  44.44205093 -110.10383606 -214.72457886 ...,   56.50108719\n",
      "  -131.72332764   84.38804626]\n",
      " [ 288.88677979 -277.25476074 -490.5708313  ...,  175.72525024\n",
      "  -196.50019836  467.42556763]\n",
      " ..., \n",
      " [-241.14767456  226.14082336  325.89718628 ...,  -45.59486771\n",
      "   226.55795288 -221.37988281]\n",
      " [  -8.15202427  145.6502533    33.30801773 ..., -147.27935791\n",
      "   -15.43331718 -206.29437256]\n",
      " [-225.9641571   250.87538147  396.88607788 ..., -133.33071899\n",
      "   170.97853088 -433.68011475]]\n",
      "\n",
      "Translation: ru->es\n",
      "\n",
      "length of ru-es vocab: 5870\n",
      "Determinant:1.06374e-22\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[-138.00456238   -6.45686722   71.60140991 ...,  -36.70297241\n",
      "    58.82127762  154.65583801]\n",
      " [  49.72098923  -52.75326538  104.88195801 ...,   20.12860298\n",
      "   -74.70955658   40.26996613]\n",
      " [  -2.66938472 -147.09407043   98.62489319 ...,   85.64072418\n",
      "    23.54691696  125.16918945]\n",
      " ..., \n",
      " [-118.95442963   13.25885868   91.0585022  ...,  -67.21045685\n",
      "    62.11876678  115.23573303]\n",
      " [ -36.5912056    65.4972229    -3.35349679 ...,  -29.58674812   53.3549614\n",
      "   113.96194458]\n",
      " [ -71.00119781 -125.49362183  112.67459106 ...,   49.41052246\n",
      "    34.73974228  -78.90220642]]\n",
      "\n",
      "Translation: ru->zh-CN\n",
      "\n",
      "length of ru-zh-CN vocab: 1266\n",
      "Determinant:0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[ 123.87176514  101.6381073   194.61276245 ...,  -42.12559891\n",
      "    96.63561249  138.75669861]\n",
      " [-744.82489014 -704.24475098 -446.41647339 ..., -491.5687561   -63.25275421\n",
      "   222.48565674]\n",
      " [  20.97368813   34.40427399  192.9274292  ..., -135.43104553\n",
      "   119.09024811  102.5777359 ]\n",
      " ..., \n",
      " [ 195.69140625   27.52499962   45.47441101 ...,  102.32037354\n",
      "     3.24064541  -41.37684631]\n",
      " [ 245.32792664  146.08032227  202.41160583 ...,   92.10801697\n",
      "    32.16794586    6.01663494]\n",
      " [ 108.89143372  119.61774445  169.33660889 ...,  119.6232605    44.22268295\n",
      "    93.17635345]]\n",
      "\n",
      "Translation: ru->de\n",
      "\n",
      "length of ru-de vocab: 5910\n",
      "Determinant:-1.0791e-19\n",
      "Fr_norm:0.0\n",
      "Inverse:[[ 231.7795105   -53.77041626   35.14373016 ...,   41.9601593   -18.7463932\n",
      "   138.1625824 ]\n",
      " [-185.92315674 -348.37637329 -128.53903198 ...,   -3.67792106\n",
      "   113.00837708  -41.82150269]\n",
      " [ 274.20281982   89.54084778   52.89003372 ...,  130.93800354\n",
      "  -106.85772705  159.0308075 ]\n",
      " ..., \n",
      " [ 195.22572327 -163.60261536   73.5228653  ..., -102.59391785\n",
      "   -55.86291504   83.46475983]\n",
      " [  13.79369545  -42.29308701   -1.58617067 ...,   57.35632324\n",
      "   -16.52289391   40.29460144]\n",
      " [  70.41092682  278.4899292   115.18925476 ...,  110.06312561\n",
      "   -41.55050659   37.66139984]]\n",
      "\n",
      "Translation: zh-CN->en\n",
      "\n",
      "length of zh-CN-en vocab: 1460\n",
      "Determinant:-0.0\n",
      "Fr_norm:0.0\n",
      "Inverse:[[  750.95532227 -2677.73120117 -2790.56835938 ...,  -500.21502686\n",
      "   6477.76611328  -906.92370605]\n",
      " [ -856.35272217  2233.87646484  2544.17041016 ...,   560.26184082\n",
      "  -5371.02587891   496.52096558]\n",
      " [-1010.84552002  2835.54589844  2717.16064453 ...,   713.1763916\n",
      "  -6876.35498047   718.14050293]\n",
      " ..., \n",
      " [ -357.97131348   629.50219727   654.39550781 ...,   254.75791931\n",
      "  -1516.64099121   115.86322784]\n",
      " [  610.44421387 -1544.09875488 -1381.81567383 ...,  -359.84481812\n",
      "   3450.50390625  -447.62716675]\n",
      " [-1167.98925781  2801.60986328  2767.17675781 ...,   756.30444336\n",
      "  -6591.30371094   868.70123291]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: zh-CN->es\n",
      "\n",
      "length of zh-CN-es vocab: 1164\n",
      "Determinant:-0.0\n",
      "Fr_norm:0.0\n",
      "Inverse:[[  17.54487991   23.9071846   -69.86971283 ...,   89.22011566\n",
      "    67.72798157  108.96387482]\n",
      " [ -19.26591682  -58.13566971  -63.12947464 ...,   12.89937305  102.1413269\n",
      "    64.83384705]\n",
      " [  53.17620087 -105.45384216  -46.82474899 ...,   29.39961052\n",
      "   285.44174194   51.69458771]\n",
      " ..., \n",
      " [ -97.70675659 -172.0501709    11.54387856 ...,  -69.68674469\n",
      "   -87.34493256  -99.78017426]\n",
      " [ 132.74069214  -67.03653717 -117.35790253 ...,   83.51582336\n",
      "   427.69055176  193.97187805]\n",
      " [ -33.97097397  -28.83506012   35.82284927 ...,   70.83348083\n",
      "   -68.67223358   97.35033417]]\n",
      "\n",
      "Translation: zh-CN->ru\n",
      "\n",
      "length of zh-CN-ru vocab: 1266\n",
      "Determinant:-0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[ -37.29304123   18.05200195  120.03998566 ..., -134.6721344    97.88696289\n",
      "    -2.2412765 ]\n",
      " [  81.02592468   48.94137955 -144.85075378 ...,   -4.63170481\n",
      "   -69.93479919   10.25763702]\n",
      " [  61.70194244 -108.61361694  -82.55732727 ...,  -18.13778687\n",
      "    68.86730194   25.89509964]\n",
      " ..., \n",
      " [  39.08507919  -40.19970322  -63.80712128 ...,   24.37394714\n",
      "    10.56565571  -40.56039429]\n",
      " [ -98.20683289   39.0988884   -53.12154007 ...,   48.00292587\n",
      "   -98.26872253   -1.27546012]\n",
      " [  12.94785118  -89.91964722   41.29096603 ...,   84.5228653    60.32333374\n",
      "   -83.64056396]]\n",
      "\n",
      "Translation: zh-CN->de\n",
      "\n",
      "length of zh-CN-de vocab: 1820\n",
      "Determinant:-0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[-167.89735413 -169.32441711  262.71853638 ...,  -49.06270218\n",
      "  -218.04176331 -502.0098877 ]\n",
      " [-211.6706543   -78.65090179  313.97622681 ...,   24.95234871\n",
      "  -260.29180908 -415.22360229]\n",
      " [-234.07113647  170.86058044  -28.66379738 ...,   49.25692368\n",
      "   -20.01120186  285.25259399]\n",
      " ..., \n",
      " [ 909.95092773  -99.72676086 -110.36309052 ..., -330.12548828\n",
      "   526.26983643  551.90856934]\n",
      " [ 923.55871582 -237.44372559  -63.26832199 ..., -316.19677734\n",
      "   187.92474365   53.57709885]\n",
      " [  54.23075104 -414.93478394  291.21899414 ..., -158.23045349\n",
      "  -240.38543701 -549.38092041]]\n",
      "\n",
      "Translation: es->en\n",
      "\n",
      "length of es-en vocab: 10422\n",
      "Determinant:-8.86887e-23\n",
      "Fr_norm:0.0\n",
      "Inverse:[[  3.66905022e+01   5.63451538e+01  -4.43629608e+01 ...,   1.47553272e+01\n",
      "   -2.23721695e+01   1.92639114e+02]\n",
      " [ -2.38301963e-01  -8.82871704e+01   1.55858719e+02 ...,   6.18005409e+01\n",
      "    6.82027817e+01  -8.13018112e+01]\n",
      " [ -9.10500641e+01   5.23132744e+01  -4.51392250e+01 ...,   3.51174103e+02\n",
      "   -7.27205811e+01  -9.86932297e+01]\n",
      " ..., \n",
      " [  2.95722256e+01  -2.66521339e+01   1.52041245e+02 ...,  -9.97995734e-01\n",
      "    5.86561394e+01   1.26562370e+02]\n",
      " [ -2.66694126e+01   1.24087509e+02  -1.58618713e+02 ...,   1.02118347e+02\n",
      "    1.51513977e+02  -4.62004089e+02]\n",
      " [  3.96808014e+01   2.40333366e+01   3.03186607e+01 ...,  -7.37969131e+01\n",
      "    1.03059483e+01   2.31150391e+02]]\n",
      "\n",
      "Translation: es->de\n",
      "\n",
      "length of es-de vocab: 11456\n",
      "Determinant:-1.67781e-22\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[-211.0153656  -109.92762756 -235.15696716 ..., -462.22366333\n",
      "  -298.97665405  -98.86308289]\n",
      " [  50.72947311   31.43056297    7.85100508 ...,   32.22510147\n",
      "    61.28936005  -22.80888176]\n",
      " [ 153.84313965  146.11160278  214.22206116 ...,  406.88845825\n",
      "   189.72543335   96.86721039]\n",
      " ..., \n",
      " [-216.62428284  -85.879776   -237.69984436 ..., -293.89746094 -273.0133667\n",
      "  -253.99163818]\n",
      " [-192.18464661  -32.1150589  -150.17906189 ..., -291.48083496\n",
      "  -243.19403076 -141.9500885 ]\n",
      " [  84.87358093  -22.03468704  134.11616516 ...,  305.0322876   173.19493103\n",
      "    64.18505859]]\n",
      "\n",
      "Translation: es->ru\n",
      "\n",
      "length of es-ru vocab: 5870\n",
      "Determinant:3.42516e-22\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[ -36.88964081  -38.66049194  171.79954529 ...,  -23.12669563\n",
      "   -56.12367249    6.87218428]\n",
      " [  53.82025909  212.07670593  -42.72406769 ..., -787.01470947\n",
      "   112.25466919   61.76227188]\n",
      " [  -6.68660975  177.28474426   32.79327393 ..., -769.54364014\n",
      "   125.00292969   -8.67141724]\n",
      " ..., \n",
      " [  38.5022583   150.08508301  -30.97211075 ..., -298.6656189   152.74972534\n",
      "   -61.62663651]\n",
      " [  51.41888809  211.19586182  -60.89271164 ..., -822.25720215\n",
      "   239.45413208  -25.49222755]\n",
      " [  19.69354248  128.50161743  -26.33551598 ..., -596.45941162\n",
      "    98.39897156   11.74662304]]\n",
      "\n",
      "Translation: es->zh-CN\n",
      "\n",
      "length of es-zh-CN vocab: 1164\n",
      "Determinant:-0.0\n",
      "Fr_norm:-0.0\n",
      "Inverse:[[  1.54408991e-01  -7.29956970e+01  -5.20634460e+01 ...,  -1.46622116e+02\n",
      "   -1.52809097e+02  -3.85142250e+01]\n",
      " [  7.74740076e+00   3.60843201e+01  -7.10157700e+01 ...,  -4.23915291e+01\n",
      "   -9.08426361e+01   3.14684830e+01]\n",
      " [  1.35625973e+01  -5.47755051e+01  -1.08091764e+01 ...,  -7.55519513e-03\n",
      "   -1.25363716e+02   2.30807434e+02]\n",
      " ..., \n",
      " [  1.06153564e+02  -2.54409866e+02   1.49036392e+02 ...,  -4.00590363e+01\n",
      "   -2.20805008e+02   1.89460587e+02]\n",
      " [  2.15465317e+02  -2.01847336e+02   9.14659595e+00 ...,  -8.39445953e+01\n",
      "   -2.12597778e+02   1.59251205e+02]\n",
      " [ -4.10690651e+01   3.38989067e+01   4.17062912e+01 ...,   8.21285019e+01\n",
      "   -1.81661606e+02   2.83516327e+02]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Manually set list of translations (embedding, lg1, lg2)\n",
    "    translations = [#('fasttext_random', 'en', 'ru'),\n",
    "                    ('fasttext_top', 'en', 'ru'),\n",
    "                    #('fasttext_random', 'en', 'de'),\n",
    "                    ('fasttext_top', 'en', 'de'),\n",
    "                    #('fasttext_random', 'en', 'es'),\n",
    "                    ('fasttext_top', 'en', 'es'),\n",
    "                    #('fasttext_random', 'en', 'zh-CN'),\n",
    "                    ('fasttext_top', 'en', 'zh-CN'),\n",
    "                    #('fasttext_random', 'de', 'en'),\n",
    "                    ('fasttext_top', 'de', 'en'),\n",
    "                    #('fasttext_random', 'de', 'es'),\n",
    "                    ('fasttext_top', 'de', 'es'),\n",
    "                    #('fasttext_random', 'de', 'ru'),\n",
    "                    ('fasttext_top', 'de', 'ru'),\n",
    "                    #('fasttext_random', 'de', 'zh-CN'),\n",
    "                    ('fasttext_top', 'de', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'en'),\n",
    "                    ('fasttext_top', 'ru', 'en'),\n",
    "                    #('fasttext_random', 'ru', 'es'),\n",
    "                    ('fasttext_top', 'ru', 'es'),\n",
    "                    #('fasttext_random', 'ru', 'zh-CN'),\n",
    "                    ('fasttext_top', 'ru', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'de'),\n",
    "                    ('fasttext_top', 'ru', 'de'),\n",
    "                    #('fasttext_random', 'zh-CN', 'en'),\n",
    "                    ('fasttext_top', 'zh-CN', 'en'),\n",
    "                    #('fasttext_random', 'zh-CN', 'es'),\n",
    "                    ('fasttext_top', 'zh-CN', 'es'),\n",
    "                    #('fasttext_random', 'zh-CN', 'ru'),\n",
    "                    ('fasttext_top', 'zh-CN', 'ru'),\n",
    "                    #('fasttext_random', 'zh-CN', 'de'),\n",
    "                    ('fasttext_top', 'zh-CN', 'de'),\n",
    "                    #('fasttext_random', 'es', 'en'),\n",
    "                    ('fasttext_top', 'es', 'en'),\n",
    "                    #('fasttext_random', 'es', 'de'),\n",
    "                    ('fasttext_top', 'es', 'de'),\n",
    "                    #('fasttext_random', 'es', 'ru'),\n",
    "                    ('fasttext_top', 'es', 'ru'),\n",
    "                    #('fasttext_random', 'es', 'zh-CN'),\n",
    "                    ('fasttext_top', 'es', 'zh-CN')\n",
    "\n",
    "                    ]\n",
    "\n",
    "    md = ''\n",
    "    for translation in translations:\n",
    "        embedding, lg1, lg2 = translation\n",
    "        # Vocab/Vectors/Dicts\n",
    "        lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "            pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      write=False)\n",
    "        lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "        lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "        print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "        # Train/Test Vocab/Vectors\n",
    "        vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "        X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                              vocab_test)\n",
    "\n",
    "        # Fit tranlation matrix to training data\n",
    "        model, history, T, D, tf, I, M = translation_matrix(X_train, y_train)\n",
    "\n",
    "        print('Inverse:'+str(I)+'\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sanity Check on Determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->ru\n",
      "\n",
      "length of en-ru vocab: 6839\n",
      "Determinant:2.03775e-19\n",
      "[ 0.67061174  0.6873163   0.85272115 ...,  1.20578921  1.40582168\n",
      "  0.93844253]\n",
      "[[  4.34536341e-04  -1.01042946e-03   1.29217806e-04 ...,   2.51814048e-03\n",
      "    2.25269631e-03  -3.78022756e-04]\n",
      " [ -2.70378281e-04   1.11204310e-04   3.61257058e-04 ...,   1.47847389e-03\n",
      "    2.56023044e-03   3.06686998e-04]\n",
      " [ -7.82030053e-04  -2.08674697e-03  -3.18972440e-03 ...,   1.43284816e-03\n",
      "    8.56383296e-04  -5.04361931e-04]\n",
      " ..., \n",
      " [  3.68732936e-03   1.84817414e-03   2.45620660e-03 ...,   4.04990744e-03\n",
      "   -1.71988842e-03  -2.58150208e-03]\n",
      " [  9.60162492e-04   5.78932850e-05   2.89971940e-03 ...,   8.86483584e-04\n",
      "   -2.09363061e-03  -8.01478338e-04]\n",
      " [ -3.22616356e-03  -2.79117911e-03  -1.80032675e-03 ...,   1.22218125e-03\n",
      "   -1.76331308e-03  -7.65946519e-04]]\n",
      "Volume of yhat matrix: inf\n",
      "\n",
      "Translation: en->de\n",
      "\n",
      "length of en-de vocab: 16693\n",
      "Determinant:-1.29322e-21\n",
      "[ 0.70435685  0.65216172  0.62163788 ...,  1.12678242  1.32142627\n",
      "  1.23906744]\n",
      "[[  2.71139224e-03  -1.48496684e-03  -1.56725768e-03 ...,  -1.17054768e-03\n",
      "   -1.34262850e-03  -1.98837882e-03]\n",
      " [  2.86348537e-03  -2.10620440e-03   2.23037554e-03 ...,  -6.03577180e-04\n",
      "    9.56599833e-04  -2.53266189e-03]\n",
      " [  5.87912276e-03  -9.92000662e-03   6.33286545e-03 ...,   9.39513731e-04\n",
      "    5.11228718e-05  -7.09268823e-03]\n",
      " ..., \n",
      " [ -6.36017649e-03   7.78413843e-03  -8.55566189e-03 ...,   9.38213780e-04\n",
      "    1.07714045e-03   8.00844096e-03]\n",
      " [ -4.13319608e-03   5.01748919e-03  -3.29270447e-03 ...,   6.99573080e-04\n",
      "   -2.63066206e-04   3.48947360e-03]\n",
      " [  1.22031802e-03   4.18335851e-03  -2.35816627e-03 ...,   3.97602853e-05\n",
      "    9.73376096e-04   5.03597199e-04]]\n",
      "Volume of yhat matrix: inf\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-26e1c462676e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0mlg2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_vocab'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0mlg2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_vectors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                       write=False)\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mlg1_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg1_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg1_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlg2_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg2_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlg2_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SkymindLabsInternship/Isomantics/code/gensim_download.py\u001b[0m in \u001b[0;36mpickle_rw\u001b[0;34m(write, *tuples)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../pickle/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Manually set list of translations (embedding, lg1, lg2)\n",
    "    translations = [#('fasttext_random', 'en', 'ru'),\n",
    "                    ('fasttext_top', 'en', 'ru'),\n",
    "                    #('fasttext_random', 'en', 'de'),\n",
    "                    ('fasttext_top', 'en', 'de'),\n",
    "                    #('fasttext_random', 'en', 'es'),\n",
    "                    ('fasttext_top', 'en', 'es'),\n",
    "                    #('fasttext_random', 'en', 'zh-CN'),\n",
    "                    ('fasttext_top', 'en', 'zh-CN'),\n",
    "                    #('fasttext_random', 'de', 'en'),\n",
    "                    ('fasttext_top', 'de', 'en'),\n",
    "                    #('fasttext_random', 'de', 'es'),\n",
    "                    ('fasttext_top', 'de', 'es'),\n",
    "                    #('fasttext_random', 'de', 'ru'),\n",
    "                    ('fasttext_top', 'de', 'ru'),\n",
    "                    #('fasttext_random', 'de', 'zh-CN'),\n",
    "                    ('fasttext_top', 'de', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'en'),\n",
    "                    ('fasttext_top', 'ru', 'en'),\n",
    "                    #('fasttext_random', 'ru', 'es'),\n",
    "                    ('fasttext_top', 'ru', 'es'),\n",
    "                    #('fasttext_random', 'ru', 'zh-CN'),\n",
    "                    ('fasttext_top', 'ru', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'de'),\n",
    "                    ('fasttext_top', 'ru', 'de'),\n",
    "                    #('fasttext_random', 'zh-CN', 'en'),\n",
    "                    ('fasttext_top', 'zh-CN', 'en'),\n",
    "                    #('fasttext_random', 'zh-CN', 'es'),\n",
    "                    ('fasttext_top', 'zh-CN', 'es'),\n",
    "                    #('fasttext_random', 'zh-CN', 'ru'),\n",
    "                    ('fasttext_top', 'zh-CN', 'ru'),\n",
    "                    #('fasttext_random', 'zh-CN', 'de'),\n",
    "                    ('fasttext_top', 'zh-CN', 'de'),\n",
    "                    #('fasttext_random', 'es', 'en'),\n",
    "                    ('fasttext_top', 'es', 'en'),\n",
    "                    #('fasttext_random', 'es', 'de'),\n",
    "                    ('fasttext_top', 'es', 'de'),\n",
    "                    #('fasttext_random', 'es', 'ru'),\n",
    "                    ('fasttext_top', 'es', 'ru'),\n",
    "                    #('fasttext_random', 'es', 'zh-CN'),\n",
    "                    ('fasttext_top', 'es', 'zh-CN')\n",
    "\n",
    "                    ]\n",
    "\n",
    "    md = ''\n",
    "    for translation in translations:\n",
    "        embedding, lg1, lg2 = translation\n",
    "        # Vocab/Vectors/Dicts\n",
    "        lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "            pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      write=False)\n",
    "        lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "        lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "        print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "        # Train/Test Vocab/Vectors\n",
    "        vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "        X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                              vocab_test)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Fit tranlation matrix to training data\n",
    "        model, history, T, D, tf, I, M = translation_matrix(X_train, y_train)\n",
    "\n",
    "        \n",
    "        y_norm = translation_results(X_test, y_test, vocab_test, T,\n",
    "                                        lg2_vectors, lg2_vocab)\n",
    "        \n",
    "        \n",
    "        #print('Volume of X matrix: '+ np.prod(X_norm)+'\\n')\n",
    "        print(y_norm)\n",
    "        print(T)\n",
    "        print('Volume of yhat matrix: '+ str(np.prod(y_norm))+'\\n')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
