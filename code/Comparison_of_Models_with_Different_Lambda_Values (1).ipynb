{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Models w/ Different Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: theano in /usr/local/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/site-packages (from theano->keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/site-packages (from theano->keras)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/site-packages (from pydrive)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/site-packages (from pydrive)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/site-packages (from pydrive)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/site-packages (from google-api-python-client>=1.2->pydrive)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/site-packages (from google-api-python-client>=1.2->pydrive)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/site-packages (from google-api-python-client>=1.2->pydrive)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/site-packages (from oauth2client>=4.0.0->pydrive)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/site-packages (from oauth2client>=4.0.0->pydrive)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/site-packages (from oauth2client>=4.0.0->pydrive)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: backports.weakref==1.0rc1 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorflow)\n",
      "Collecting bottleneck\n",
      "  Using cached Bottleneck-1.2.1.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from bottleneck)\n",
      "Building wheels for collected packages: bottleneck\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Dungeoun/Library/Caches/pip/wheels/4d/56/b2/36b69796ed42dbb94d921772e9d9dedeb90e62905b1069f09a\n",
      "Successfully built bottleneck\n",
      "Installing collected packages: bottleneck\n",
      "Successfully installed bottleneck-1.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip3 install keras\n",
    "! pip3 install matplotlib\n",
    "! pip3 install pandas\n",
    "! pip3 install seaborn\n",
    "! pip3 install pydrive\n",
    "! pip3 install tensorflow\n",
    "! pip3 install bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import nregularizer\n",
    "import numpy as np\n",
    "from gensim_download import pickle_rw\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy.linalg\n",
    "\n",
    "from numpy.linalg import det\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import bottleneck as bn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dict(vocab, vectors):\n",
    "    \"\"\"Make dictionary of vocab and vectors\"\"\"\n",
    "    return {vocab[i]: vectors[i] for i in range(len(vocab))}\n",
    "\n",
    "\n",
    "def vocab_train_test(embedding, lg1, lg2, lg1_vocab):\n",
    "    \"\"\"Create training and test vocabularies\"\"\"\n",
    "    if embedding == 'zeroshot':\n",
    "        with open('../data/zeroshot/transmat/data/' +\n",
    "                  'OPUS_en_it_europarl_train_5K.txt') as f:\n",
    "            vocab_train = [(_.split(' ')[0], _.split(' ')[1])\n",
    "                           for _ in f.read().split('\\n')[:-1]]\n",
    "        with open('../data/zeroshot/transmat/data/' +\n",
    "                  'OPUS_en_it_europarl_test.txt') as f:\n",
    "            vocab_test = [(_.split(' ')[0], _.split(' ')[1])\n",
    "                          for _ in f.read().split('\\n')[:-1]]\n",
    "\n",
    "    elif embedding in ['fasttext_random', 'fasttext_top']:\n",
    "        embedding, split = embedding.split('_')\n",
    "        lg1_lg2, lg2_lg1 = pickle_rw((lg1 + '_' + lg2, 0),\n",
    "                                     (lg2 + '_' + lg1, 0), write=False)\n",
    "        # T = Translation, R = Reverse (translated and then translated back)\n",
    "        # Create vocab from 2D translations\n",
    "        vocab_2D = []\n",
    "        for lg1_word in lg1_vocab:\n",
    "            # Translate lg1_word\n",
    "            if lg1_word in lg1_lg2:\n",
    "                lg1_word_T = lg1_lg2[lg1_word]\n",
    "\n",
    "                # Check if translated word (or lowercase) is in lg2_lg1\n",
    "                if lg1_word_T in lg2_lg1.keys():\n",
    "                    lg1_word_R = lg2_lg1[lg1_word_T]\n",
    "                elif lg1_word_T.lower() in lg2_lg1.keys():\n",
    "                    lg1_word_T = lg1_word_T.lower()\n",
    "                    lg1_word_R = lg2_lg1[lg1_word_T]\n",
    "                else:\n",
    "                    lg1_word_R = None\n",
    "\n",
    "                # Check if lg1_word and lg1_word_R are equal (lowercase)\n",
    "                if lg1_word_R:\n",
    "                    if lg1_word.lower() == lg1_word_R.lower():\n",
    "                        vocab_2D.append((lg1_word, lg1_word_T))\n",
    "        print('length of '+ lg1+'-'+ lg2+ ' vocab: '+str(len(vocab_2D)))\n",
    "\n",
    "        #Create Train/Test vocab\n",
    "\n",
    "        if split == 'random':\n",
    "            sample = np.random.choice(len(vocab_2D), 6500, replace=False)\n",
    "            vocab_train = np.asarray(vocab_2D)[sample[:5000]].tolist()\n",
    "            vocab_test = np.asarray(vocab_2D)[sample[5000:]].tolist()\n",
    "        elif split == 'top':\n",
    "#             sample = np.random.choice(range(6500), 6500, replace=False)\n",
    "            vocab_train = np.asarray(vocab_2D)[:5000, :].tolist()\n",
    "            vocab_test = np.asarray(vocab_2D)[:1500, :].tolist()\n",
    "            \n",
    "#             sample = np.random.choice(range(6500), 6500, replace=False)\n",
    "#             vocab_train = np.asarray(vocab_2D)[:700, :].tolist()\n",
    "#             vocab_test = np.asarray(vocab_2D)[:200, :].tolist()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # if split == 'random':\n",
    "        #     sample = np.random.choice(len(vocab_2D), 900, replace=False)\n",
    "        #     vocab_train = np.asarray(vocab_2D)[sample[:700]].tolist()\n",
    "        #     vocab_test = np.asarray(vocab_2D)[sample[700:]].tolist()\n",
    "        # elif split == 'top':\n",
    "        #     sample = np.random.choice(range(900), 900, replace=False)\n",
    "        #     vocab_train = np.asarray(vocab_2D)[:700, :].tolist()\n",
    "        #     vocab_test = np.asarray(vocab_2D)[:200, :].tolist()\n",
    "        # else:\n",
    "        #     pass\n",
    "\n",
    "    return vocab_train, vocab_test\n",
    "\n",
    "\n",
    "def vectors_train_test(vocab_train, vocab_test):\n",
    "    \"\"\"Create training and test vectors\"\"\"\n",
    "    X_train, y_train = zip(*[(lg1_dict[lg1_word], lg2_dict[lg2_word])\n",
    "                             for lg1_word, lg2_word in vocab_train])\n",
    "    X_test, y_test = zip(*[(lg1_dict[lg1_word], lg2_dict[lg2_word])\n",
    "                           for lg1_word, lg2_word in vocab_test])\n",
    "    return map(np.asarray, (X_train, X_test, y_train, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def translation_matrix(X_train, y_train, l):\n",
    "    \"\"\"Fit translation matrix T\"\"\"\n",
    "    #def norm_reg(weight_matrix):\n",
    "     #   return 0.01 * np.linalg.norm(np.matrix(np.subtract(np.matmul(weight_matrix,weight_matrix.T,np.matmul(weight_matrix.T,weight_matrix))),'fro')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, use_bias=False, input_shape=(X_train.shape[1],),kernel_regularizer=nregularizer.l3(l)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=20,\n",
    "                        verbose=False)\n",
    "    T = model.get_weights()[0]\n",
    "    \n",
    "    M = np.matrix(T)\n",
    "\n",
    "    Fr_norm = np.linalg.norm(np.matrix(np.subtract(np.matmul(M,np.transpose(M)),np.matmul(np.transpose(M),M))),'fro')\n",
    "\n",
    "    #print (\"Determinant:\"+str(D))\n",
    "    \n",
    "    #print (\"Fr_norm:\"+str(Fr_norm))\n",
    "\n",
    "    return T, Fr_norm \n",
    "\n",
    "def translation_accuracy(X_test, y_test, T):\n",
    "    \"\"\"Get predicted matrix 'yhat' using 'T' and find translation accuracy\"\"\"\n",
    "    # yhat\n",
    "    yhat = X_test.dot(T)\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        #if yhat[i,:].all() == y_test[i,:].all():\n",
    "        if np.array_equal(yhat[i,:],y_test[i,:]) == True:\n",
    "            count = count + 1\n",
    "    accuracy = count/len(y_test)*100\n",
    "    return accuracy\n",
    "\n",
    "def svd(T):\n",
    "    \"\"\"Perform SVD on the translation matrix 'T' \"\"\"\n",
    "    U, s, Vh = numpy.linalg.svd(T, full_matrices=False )\n",
    "    return U, s, Vh\n",
    "\n",
    "def T_svd_EDA(s):\n",
    "    \"\"\"Perform SVD on the translation matrix 'T' \"\"\"\n",
    "    plt.hist(s, bins='auto', range = (0,1),normed = 1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize(matrix):\n",
    "    \"\"\"Normalize the rows of a matrix\"\"\"\n",
    "    matrix_norm = np.linalg.norm(matrix, axis=1)\n",
    "    matrix_normed = matrix / np.repeat(matrix_norm, matrix.shape[1]). \\\n",
    "        reshape(matrix.shape)\n",
    "    return matrix_norm, matrix_normed\n",
    "\n",
    "\n",
    "def translation_results(X, y, vocab, T, lg2_vectors, lg2_vocab):\n",
    "    \"\"\"X, y, vocab - The training or test data that you want results for\n",
    "    T - The translation matrix\n",
    "    lg2_vectors, lg2_vocab - Foreign language used to find the nearest neighbor\n",
    "    \"\"\"\n",
    "    print(\"in translation results.... and doing data prep\")\n",
    "    # Data Prep on Inputs\n",
    "    X_word, y_word = zip(*vocab)\n",
    "    X_norm, X_normed = normalize(X)\n",
    "    y_norm, y_normed = normalize(y)\n",
    "    lg2_vectors_norm, lg2_vectors_normed = normalize(lg2_vectors)\n",
    "\n",
    "    print(\"yhat\")\n",
    "    # yhat\n",
    "    yhat = X.dot(T)\n",
    "    yhat_norm, yhat_normed = normalize(yhat)\n",
    "\n",
    "    #X_norm = normalize(X)\n",
    "\n",
    "    print(\"neg_cosine and \")\n",
    "    # Nearest Neighbors\n",
    "    neg_cosine = -yhat_normed.dot(lg2_vectors_normed.T)\n",
    "    \n",
    "    print(\"ranked neighbor indices\")\n",
    "    #ranked_neighbor_indices = np.argsort(neg_cosine, axis=1)\n",
    "    ranked_neighbor_indices = bn.argpartition(neg_cosine, len(neg_cosine), axis = 1 )\n",
    "    # Nearest Neighbor\n",
    "    print(\"step 1:nn indices...\")\n",
    "    nearest_neighbor_indices = ranked_neighbor_indices[:, 0]\n",
    "    print(\"step 2:yhat_neighbor...\")\n",
    "    yhat_neighbor = lg2_vectors[nearest_neighbor_indices, :]\n",
    "    print(\"step 3:yhat_neighbor_norm...\")\n",
    "    yhat_neighbor_norm, yhat_neighbor_normed = normalize(yhat_neighbor)\n",
    "    print(\"step 4:yhat_neighbor_word...\")\n",
    "    yhat_neighbor_word = np.asarray(lg2_vocab)[nearest_neighbor_indices]\n",
    "\n",
    "    # Results DF\n",
    "    print(\"step 5:making df....\")\n",
    "    cols = ['X_norm', 'y_norm', 'yhat_norm', 'yhat_neighbor_norm',\n",
    "            'X_word', 'y_word', 'yhat_neighbor_word']\n",
    "    results_df = pd.DataFrame({'X_norm': X_norm,\n",
    "                               'y_norm': y_norm,\n",
    "                               'yhat_norm': yhat_norm,\n",
    "                               'yhat_neighbor_norm': yhat_neighbor_norm,\n",
    "                               'X_word': X_word,\n",
    "                               'y_word': y_word,\n",
    "                               'yhat_neighbor_word': yhat_neighbor_word,})\n",
    "    results_df = results_df[cols]\n",
    "    results_df['neighbor_correct'] = results_df.y_word == \\\n",
    "        results_df.yhat_neighbor_word\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def T_norm_EDA(results_df):\n",
    "    \"\"\"Plot result norms side-by-side\"\"\"\n",
    "    \n",
    "    test_size = results_df.shape[0]\n",
    "    test_accuracy = results_df.neighbor_correct.mean()\n",
    "\n",
    "    #print('Test Accuracy: '+str(test_accuracy)+'\\n')\n",
    "\n",
    "    #plot_data = ['X_norm', 'y_norm', 'yhat_norm', 'yhat_neighbor_norm']\n",
    "    # f, ax = plt.subplots(len(plot_data), sharex=True, sharey=True,\n",
    "    #                      figsize=(10, 10))\n",
    "    # for i, d in enumerate(plot_data):\n",
    "    #     ax[i].hist(results_df[d], bins=100)\n",
    "    #     ax[i].axis('off')\n",
    "    #     title = '{}: mean={}, std={}'.format(d, round(results_df[d].mean(), 2), round(results_df[d].std(), 2))\n",
    "    #     ax[i].set_title(title)\n",
    "    # f.subplots_adjust(hspace=0.7)\n",
    "    # plt.savefig('../images/' + lg1 + '_' + lg2 + '_' + embedding +\n",
    "    #             '_T_norm.png')\n",
    "    # plt.close('all')\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def T_pca_EDA(T):\n",
    "    \"\"\"PCA on matrix T\"\"\"\n",
    "    T_ss = StandardScaler().fit_transform(T)\n",
    "    pca = PCA().fit(T_ss)\n",
    "    n = pca.n_components_\n",
    "\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.xlim((0, n))\n",
    "    # plt.ylim((0, 1))\n",
    "    # plt.plot(range(n + 1), [0] + np.cumsum(pca.explained_variance_ratio_).\n",
    "    #          tolist())\n",
    "    # plt.plot(range(n + 1), np.asarray(range(n + 1)) / n)\n",
    "    # plt.xlabel('Number of Eigenvectors')\n",
    "    # plt.ylabel('Explained Variance')\n",
    "    # plt.savefig('../images/' + lg1 + '_' + lg2 + '_' + embedding +\n",
    "    #             '_T_isotropy.png')\n",
    "    # plt.close('all')\n",
    "\n",
    "    isotropy = (1 - sum(np.cumsum(pca.explained_variance_ratio_) * 1 / n)) / .5\n",
    "    return isotropy\n",
    "\n",
    "\n",
    "def T_report_results(embedding, lg1, lg2, lg1_vectors, lg2_vectors,\n",
    "                     X_train, X_test, D, results_df, isotropy):\n",
    "    md = '## ' + lg1.title() + ' to ' + lg2.title() + ' ' + \\\n",
    "        embedding.title() + '  \\n'\n",
    "    md += '- ' + lg1.title() + ' Vocabulary Size = ' + \\\n",
    "        '{:,.0f}'.format(lg1_vectors.shape[0]) + '  \\n'\n",
    "    md += '- ' + lg1.title() + ' Embedding Length = ' + \\\n",
    "        '{:,.0f}'.format(lg1_vectors.shape[1]) + '  \\n'\n",
    "    md += '- ' + lg2.title() + ' Vocabulary Size = ' + \\\n",
    "        '{:,.0f}'.format(lg2_vectors.shape[0]) + '  \\n'\n",
    "    md += '- ' + lg2.title() + ' Embedding Length = ' + \\\n",
    "        '{:,.0f}'.format(lg2_vectors.shape[1]) + '  \\n'\n",
    "    md += '- Train Size = ' + '{:,.0f}'.format(X_train.shape[0]) + '  \\n'\n",
    "    md += '- Test Size = ' + '{:,.0f}'.format(X_test.shape[0]) + '  \\n'\n",
    "    md += '- Determinant = ' + '{:,.0f}'.format(D) + '  \\n'\n",
    "\n",
    "    md += '- <b>Test Accuracy = ' + \\\n",
    "        '{:,.1%}'.format(results_df.neighbor_correct.mean()) + '</b>  \\n\\n'\n",
    "\n",
    "\n",
    "\n",
    "    md += '#### Test L2 Norms  \\n'\n",
    "    md += '- X_norm: L2 norms for ' + lg1.title() + ' test vectors  \\n'\n",
    "    md += '- y_norm: L2 norms for ' + lg2.title() + ' test vectors  \\n'\n",
    "    md += '- yhat_norm: L2 norms for X.dot(T) test vectors ' + \\\n",
    "        '(T = translation matrix)  \\n'\n",
    "    md += '- yhat_neighbor norm: L2 norms for nearest neighbor' + \\\n",
    "        'to X.dot(T) in y test vectors  \\n'\n",
    "    md += '![](../images/' + lg1 + '_' + lg2 + '_' + embedding + \\\n",
    "        '_T_norm.png)  \\n\\n'\n",
    "\n",
    "    md += '#### Translation Matrix Isotropy  \\n'\n",
    "    md += '- Isotropy = ' + '{:,.1%}'.format(isotropy) + '  \\n'\n",
    "    md += '![](../images/' + lg1 + '_' + lg2 + '_' + embedding + \\\n",
    "        '_T_isotropy.png)  \\n\\n'\n",
    "\n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: en->en\n",
      "\n",
      "length of en-en vocab: 49999\n",
      "in translation results.... and doing data prep\n",
      "yhat\n",
      "neg_cosine and \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8b8ecde0bffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         results_df = translation_results(X_test, y_test, vocab_test, T,\n\u001b[0;32m--> 107\u001b[0;31m                                          lg2_vectors, lg2_vocab)\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_norm_EDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-49b615803e32>\u001b[0m in \u001b[0;36mtranslation_results\u001b[0;34m(X, y, vocab, T, lg2_vectors, lg2_vocab)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"neg_cosine and \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# Nearest Neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mneg_cosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0myhat_normed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg2_vectors_normed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ranked neighbor indices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Manually set list of translations (embedding, lg1, lg2)\n",
    "    translations = [#('fasttext_random', 'en', 'ru'),\n",
    "                    ('fasttext_top', 'en', 'en'),\n",
    "                    ('fasttext_top', 'en', 'ru'),\n",
    "                    #('fasttext_random', 'en', 'de'),\n",
    "                    ('fasttext_top', 'en', 'de'),\n",
    "                    #('fasttext_random', 'en', 'es'),\n",
    "                    ('fasttext_top', 'en', 'es'),\n",
    "                    #('fasttext_random', 'en', 'zh-CN'),\n",
    "                    ('fasttext_top', 'en', 'zh-CN'),\n",
    "        \n",
    "        \n",
    "        \n",
    "                     #('fasttext_random', 'ru', 'en'),\n",
    "                    ('fasttext_top', 'ru', 'en'),\n",
    "                    #('fasttext_random', 'ru', 'es'),\n",
    "                    ('fasttext_top', 'ru', 'ru'),\n",
    "                    ('fasttext_top', 'ru', 'de'),\n",
    "                    ('fasttext_top', 'ru', 'es'),\n",
    "                    #('fasttext_random', 'ru', 'zh-CN'),\n",
    "                    ('fasttext_top', 'ru', 'zh-CN'),\n",
    "                    #('fasttext_random', 'ru', 'de'),\n",
    "                    \n",
    "        \n",
    "        \n",
    "                    #('fasttext_random', 'de', 'en'),\n",
    "                    ('fasttext_top', 'de', 'en'),\n",
    "                    #('fasttext_random', 'de', 'es'),\n",
    "                    ('fasttext_top', 'de', 'ru'), \n",
    "                    #('fasttext_random', 'de', 'ru'),\n",
    "                    ('fasttext_top', 'de', 'de'),\n",
    "                    ('fasttext_top', 'de', 'es'),\n",
    "                    #('fasttext_random', 'de', 'zh-CN'),\n",
    "                    ('fasttext_top', 'de', 'zh-CN'),\n",
    "        \n",
    "        \n",
    "        \n",
    "                    #('fasttext_random', 'es', 'en'),\n",
    "                    ('fasttext_top', 'es', 'en'),\n",
    "                    #('fasttext_random', 'es', 'de'),\n",
    "                    ('fasttext_top', 'es', 'ru'),\n",
    "                    ('fasttext_top', 'es', 'de'),\n",
    "                    #('fasttext_random', 'es', 'ru'),\n",
    "                    ('fasttext_top', 'es', 'es'),\n",
    "                    #('fasttext_random', 'es', 'zh-CN'),\n",
    "                    ('fasttext_top', 'es', 'zh-CN'),\n",
    "        \n",
    "                \n",
    "        \n",
    "                    #('fasttext_random', 'zh-CN', 'en'),\n",
    "                    ('fasttext_top', 'zh-CN', 'en'),\n",
    "                    #('fasttext_random', 'zh-CN', 'es'),\n",
    "                    ('fasttext_top', 'zh-CN', 'ru'),\n",
    "                    ('fasttext_top', 'zh-CN', 'de'),\n",
    "                    ('fasttext_top', 'zh-CN', 'es'),\n",
    "                    #('fasttext_random', 'zh-CN', 'ru'),\n",
    "                    ('fasttext_top', 'zh-CN', 'zh-CN'),\n",
    "                    #('fasttext_random', 'zh-CN', 'de'),\n",
    "        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    ]\n",
    "   \n",
    "    md = ''\n",
    "    for translation in translations:\n",
    "        embedding, lg1, lg2 = translation\n",
    "        # Vocab/Vectors/Dicts\n",
    "        lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "            pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      write=False)\n",
    "        lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "        lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "        print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "        # Train/Test Vocab/Vectors\n",
    "        vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "        X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                              vocab_test)\n",
    " \n",
    "        \n",
    "        # Fit tranlation matrix to training data\n",
    "        \n",
    "        T, fr_norm = translation_matrix(X_train, y_train, 1) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        T1, fr_norm1 = translation_matrix(X_train, y_train, 0.1)\n",
    "        \n",
    "        T01, fr_norm01 = translation_matrix(X_train, y_train, 0.01)\n",
    "        \n",
    "        T001, fr_norm001 = translation_matrix(X_train, y_train, 0.001)\n",
    "        \n",
    "        T0001, fr_norm0001 = translation_matrix(X_train, y_train, 0.0001)\n",
    "        \n",
    "        T00001, fr_norm00001 = translation_matrix(X_train, y_train, 0.00001)\n",
    "        \n",
    "        # Test Data Results\n",
    "        \n",
    "        results_df = translation_results(X_test, y_test, vocab_test, T,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy = T_norm_EDA(results_df)\n",
    "        \n",
    "#         test_accuracy = translation_accuracy(X_test, y_test, T)\n",
    "        \n",
    "        print(test_accuracy)\n",
    "        \n",
    "     \n",
    "        results_df1 = translation_results(X_test, y_test, vocab_test, T1,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy1 = T_norm_EDA(results_df1)\n",
    "\n",
    "#         test_accuracy = translation_accuracy(X_test, y_test, T1)\n",
    "        \n",
    "        print(test_accuracy1)\n",
    "        \n",
    "        \n",
    "        results_df01 = translation_results(X_test, y_test, vocab_test, T01,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy01 = T_norm_EDA(results_df01)\n",
    "        \n",
    "        print(test_accuracy01)\n",
    "        \n",
    "        \n",
    "        results_df001 = translation_results(X_test, y_test, vocab_test, T001,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy001 = T_norm_EDA(results_df001)\n",
    "        \n",
    "        print(test_accuracy001)\n",
    "    \n",
    "        \n",
    "        \n",
    "        results_df0001 = translation_results(X_test, y_test, vocab_test, T0001,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy0001 = T_norm_EDA(results_df0001)\n",
    "        \n",
    "        \n",
    "        print(test_accuracy0001)\n",
    "        \n",
    "        results_df00001 = translation_results(X_test, y_test, vocab_test, T00001,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        test_accuracy00001 = T_norm_EDA(results_df00001)\n",
    "        \n",
    "        print(test_accuracy00001)\n",
    "        #Plot the line graphs\n",
    "        \n",
    "        \n",
    "        Org_Acc = [test_accuracy ,test_accuracy ,test_accuracy ,test_accuracy, test_accuracy]\n",
    "        \n",
    "        New_Acc = []\n",
    "        New_Acc.append(test_accuracy1)\n",
    "        New_Acc.append(test_accuracy01)\n",
    "        New_Acc.append(test_accuracy001)\n",
    "        New_Acc.append(test_accuracy0001)\n",
    "        New_Acc.append(test_accuracy00001)\n",
    "        \n",
    "        \n",
    "        #New_Acc = [test_accuracy1 ,test_accuracy01 ,test_accuracy001 ,test_accuracy0001, test_accuracy00001]\n",
    "        \n",
    "        Fr_Norm = [fr_norm1, fr_norm01, fr_norm001, fr_norm0001, fr_norm00001]\n",
    "        \n",
    "        \n",
    "#         Org_Acc_df =pd.DataFrame(Org_Acc)\n",
    "#         Org_Acc_df.columns =['0.1', '0.01', '0.001', '0.0001', '0.00001']\n",
    "#         New_Acc_df =pd.DataFrame(New_Acc)\n",
    "#         New_Acc_df.columns =['0.1', '0.01', '0.001', '0.0001', '0.00001']\n",
    "#         Fr_Norm_df =pd.DataFrame(Fr_norm)\n",
    "#         Fr_Norm_df.columns =['0.1', '0.01', '0.001', '0.0001', '0.00001']\n",
    "        \n",
    "        Org_Acc_df =pd.DataFrame(Org_Acc, index =['0.1', '0.01', '0.001', '0.0001', '0.00001'], columns = ['Org_Acc'], )\n",
    "        New_Acc_df =pd.DataFrame(New_Acc, index =['0.1', '0.01', '0.001', '0.0001', '0.00001'], columns = ['New_Acc'], )\n",
    "        Fr_Norm_df =pd.DataFrame(Fr_Norm, index =['0.1', '0.01', '0.001', '0.0001', '0.00001'], columns = ['Fr_Norm'], )\n",
    "\n",
    "        ax = Org_Acc_df.plot(title=lg1+'->'+lg2+' Accuracies')\n",
    "        New_Acc_df.plot(ax=ax)\n",
    "        \n",
    "        ax = Fr_Norm_df.plot(title=lg1+'->'+lg2+' Frobenius Norm')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = Org_Acc_df.plot()\n",
    "New_Acc_df.plot(ax=ax)\n",
    "ax = Fr_Norm_df.plot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Org_Acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.00001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.1  0.01  0.001  0.0001  0.00001\n",
       "org  0.0   0.0  0.045   0.485     0.61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "New_Acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.00001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.1  0.01  0.001  0.0001  0.00001\n",
       "org  0.0   0.0    0.0     0.0      0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Org_Acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.00001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>1.293459</td>\n",
       "      <td>1.355856</td>\n",
       "      <td>1.982327</td>\n",
       "      <td>5.207896</td>\n",
       "      <td>11.685128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.1      0.01     0.001    0.0001    0.00001\n",
       "org  1.293459  1.355856  1.982327  5.207896  11.685128"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fr_Norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD3CAYAAAAdfCMIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x142c784a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD3CAYAAAD7VehMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjBWAJERArGEiAiUjCWABGRgv1/slXRcry6epsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14338be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = np.transpose(Org_Acc_df).plot()\n",
    "np.transpose(New_Acc_df).plot(ax=ax)\n",
    "ax = np.transpose(Fr_Norm_df).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.tseries' has no attribute 'pylab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8c0b1e25508d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.tseries' has no attribute 'pylab'"
     ]
    }
   ],
   "source": [
    "pd.tseries.pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_cosine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-99e89b53c658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneg_cosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'neg_cosine' is not defined"
     ]
    }
   ],
   "source": [
    "neg_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
